{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica para Sentiment Analysis\n",
    "\n",
    "importa panda para cargar datos en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data frame \n",
    "import numpy as np  # multidimensional array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar datos del archivo local de 50 000 con 25 x 10^5 negativos y otros positivos\n",
    "\n",
    "data_df = pd.read_csv('shuffled_movie_data.csv',error_bad_lines =False)\n",
    "data_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta primera parte vamos a cargar los datos que tenemos con columnas 'Review' y 'sentiment' los que son texto de la opinion de un video y la conclusion en sentiment\n",
    "- 1 : si es positiva la opinion\n",
    "- 0 : si es negativa la opinion\n",
    "de lo anteriormente expuesto, podemos notar que tenemos 50 mil de los cuales 25 son positivos y 25 mil son opiniones negativas de acuerdo a la web\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142–150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de los datos\n",
    "\n",
    "ahora vamos a definir nuestro procesamiento de datos para la mejor manipulacion \n",
    " del texto asi, usaremos un tokonizer para sacar la raiz de las palabras derivadas \n",
    " asi como tambien usaremos un delimitador de palabras para eliminar los articulos, \n",
    " pronnombres y algunos emoticones que sean importantes las extraeremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importar al algoritmo stemmer de nltk para eliminar y \n",
    "convertir las palbras a raiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# importar el corpus de los stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import re # importar la expresion regular para substrings y thml tags\n",
    "\n",
    "ex = '!'\n",
    "stop = stopwords.words('english')[17:] #para texto en ingles\n",
    "#print stopwords.words('english')[:17]\n",
    "porter = PorterStemmer() #algoritmo \n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '',text) #eliminar lasa etiquetas html\n",
    "    text = re.sub('!',' ! ',text)\n",
    "    #print text\n",
    "    emoticones = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower()) #encontrar los emoticones    \n",
    "    exclamation = re.findall('\\!',text.lower()) # encontrar los signos de exclamacion\n",
    "    no_words = re.findall('no',text.lower())\n",
    "    #print no_words\n",
    "    text = re.sub('[\\W]+',' ',text.lower())+' '.join(emoticones).replace('-','') #+' '.join(exclamation).replace('',' ') # agregar los emoticones al final sin -\n",
    "    #print text\n",
    "    text = [w for w in text.split() if w not in stop] # dividir si no es stopword\n",
    "    tokenized = [porter.stem(w) for w in text] # aplicando el stemmer\n",
    "    if(len(no_words) > 0):\n",
    "        text.append(no_words[0])\n",
    "    if(len(exclamation)):\n",
    "        text.append(exclamation[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos probar nuestra funcion implemeantada anteriormente con un ejemplo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'cool', 'ah', 'kidding', 'great:)', ':(', 'no', '!']\n"
     ]
    }
   ],
   "source": [
    "print tokenizer('</body>This :) is a <a> test!, cool ah!, no just kidding :(<html> that is great</br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bien ahora vamos a pasar al Aprendizaje ya que logramos hacer el precesamiento exitosamente asi que vamos , manos la obra\n",
    "## Aprendizaje con  SciKit\n",
    "\n",
    "Primero, definimos un generador, que retorna el contenido del documento con su correspondiente clase etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_doc(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) #salter la cabecera // next lee la columan y lista en orden\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label # funcion generador con texto y tag{1,0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora vamos probar lo anteriormente implementado del generador , ojo que este es solo un generador de un doc primer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_doc(path='shuffled_movie_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementacion del minibatch(mini Lote)\n",
    "\n",
    " funcion que recupera un especifico numero (size)de lotes\n",
    " documentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size): # funcion get_minibatch\n",
    "    docs, y = [], [] # crear variables locales\n",
    "    for _ in range(size): \n",
    "        text, label = next(doc_stream) # recorrer con texto y tags\n",
    "        docs.append(text)\n",
    "        y.append(label)\n",
    "    return docs, y # return de values of text an tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# para obtener en un arreglo de tamaño 1 se muestra acontinuacion \n",
    "ar = get_minibatch(stream_doc(path='shuffled_movie_data.csv'), size= 50000) # get string of text\n",
    "#print ar\n",
    "\n",
    "#print ar[0][0]\n",
    "print '->', ar[1][:10]\n",
    "#print tokenizer(ar) # show text in tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "una vez tokenizado nuestras muestras el siguiente paso es extraer nuestras proppias caracteristicas \n",
    "de acuerdo al link descrito mas abajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora vamos hacer uso del 'hashing trick' como se explica\n",
    "  en http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html\n",
    "  es un metodo de scikit-learn que convierte una collecion (textos) a una matriz\n",
    "  de ocurrencias de tipo esparsa como : https://stackoverflow.com/questions/8673035/what-is-feature-hashing-hashing-trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.867534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.875197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5.062595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.761200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.174387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.181784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B  C   D  E         F  Y\n",
       "0   8  14  1   1  0  4.867534  1\n",
       "1  13  10  1  15  1  4.875197  0\n",
       "2  14  21  1   6  1  5.062595  0\n",
       "3   4   0  0   7  0  3.761200  1\n",
       "4   4   2  0   3  0  4.174387  0\n",
       "5   9   3  1   6  0  4.290459  1\n",
       "6  15   4  1   7  0  5.181784  1\n",
       "7   4   4  1   1  1  4.304065  1\n",
       "8   6   3  1   4  1  4.204693  1\n",
       "9  10   4  1   0  1  4.406719  1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exportar la libreria HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer \n",
    "# hacer uso del hashing vectorizer de 2²21 = 2097152 caracteristicas\n",
    "vect = HashingVectorizer(decode_error = 'ignore',n_features = 2**21, preprocessor = None, tokenizer = tokenizer) \n",
    "\n",
    "# Excercise 1: define new features according to https://web.stanford.edu/~jurafsky/slp3/5.pdf\n",
    "# para este ejercicio vamos a clasificar nuestras propias caracteristicas que son 6 de acuerdo al pdf\n",
    "# estos son : positives_words, negatives_words, 1st and 2nd words, no word, exclamation y ln(counts words)\n",
    "# tambien tomaremos encuenta otras caracteristicas como los emoticones positivos y negativos\n",
    "\n",
    "from nltk.corpus import opinion_lexicon\n",
    "#from nltk.tokenize import treebank\n",
    "\n",
    "def my_feature(sentence):\n",
    "    \n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    pronouns = 0\n",
    "    no_words = 0\n",
    "    excla_words = 0\n",
    "\n",
    "    tokenized_sent = [word.lower() for word in tokenizer(sentence)]\n",
    "    # creamos lista de nuevas caracteristicas y\n",
    "    y = []\n",
    "    for word in tokenized_sent:\n",
    "        #print word\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words +=1\n",
    "        elif word in opinion_lexicon.negative():\n",
    "            neg_words += 1\n",
    "        elif word in ('i','me','my','myself','we','you','your','yours','myself','our','ours','yourself','yourselves'):\n",
    "            pronouns += 1\n",
    "            \n",
    "        if word =='no':\n",
    "            no_words = 1\n",
    "        elif word == '!':\n",
    "            excla_words = 1\n",
    "    \n",
    "    \n",
    "    y.append(pos_words) # A    \n",
    "    y.append(neg_words) # B\n",
    "    y.append(no_words)  # C\n",
    "    y.append(pronouns)  # D\n",
    "    y.append(excla_words) # E\n",
    "    y.append(np.log(len(tokenized_sent))) # F\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "n_items = 1000 # veces el numero es un buen rango rapido\n",
    "matrix = [] # matriz para almacenar las nuevas caracteristicas\n",
    "sent = []\n",
    "#loop for para recorrer todos los 10 texts\n",
    "for i in range(n_items):\n",
    "    car = my_feature(ar[0][i])\n",
    "    car.append(ar[1][i])     \n",
    "    matrix.append(car)\n",
    "\n",
    "'''\n",
    "for j in range(n_items):\n",
    "    print matrix[j]\n",
    "'''    \n",
    "\n",
    "# creamos un nuevo dataFrame\n",
    "# A: numero de positive words\n",
    "# B: numero de negative words\n",
    "# C: if exits 'no' word in the text\n",
    "# D: numero de pronombres 1ra y 2da persona\n",
    "# E: si existe signo de exclamacion\n",
    "# F: ln(count(words))\n",
    "df = pd.DataFrame(matrix,columns=list('ABCDEFY'))    \n",
    "df.shape\n",
    "# mostrar los elementos que tiene df\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos los datos en un archivo csv\n",
    "df.to_csv('6Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f**k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7.163947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.396949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.523562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.302619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.468060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment   X1  X2  \\\n",
       "49995  OK, lets start with the best. the building. al...          0   92  50   \n",
       "49996  The British 'heritage film' industry is out of...          0  106  56   \n",
       "49997  I don't even know where to begin on this one. ...          0   36  12   \n",
       "49998  Richard Tyler is a little boy who is scared of...          0   37  22   \n",
       "49999  I waited long to watch this movie. Also becaus...          1   18   3   \n",
       "\n",
       "       X3  X4  X5        X6  \n",
       "49995   1   7   0  7.163947  \n",
       "49996   1   0   1  7.396949  \n",
       "49997   1   4   1  6.523562  \n",
       "49998   1   0   0  6.302619  \n",
       "49999   0   3   0  5.468060  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way to extract the data\n",
    "positivos = opinion_lexicon.positive()\n",
    "negativos = opinion_lexicon.negative()\n",
    "\n",
    "#total_df = pd.DataFrame(columns=['X1','X2','X3','X4','X5','X6'])\n",
    "total_df = data_df\n",
    "total_df['X1'] = 0\n",
    "total_df['X2'] = 0\n",
    "\n",
    "\n",
    "#negativos[467] = 'bull'\n",
    "#negativos[1559] = 'fuck'\n",
    "print negativos[1559]\n",
    "\n",
    "for i in range(len(positivos)):\n",
    "    #print positivos[i]\n",
    "    contar = total_df['review'].str.count(positivos[i])\n",
    "    total_df['X1'] = contar + total_df['X1']\n",
    "\n",
    "for i in range(len(negativos)):\n",
    "    #print negativos[i]\n",
    "    if(i != 467 and i != 1559):\n",
    "        contar = total_df['review'].str.count(negativos[i])\n",
    "        total_df['X2'] = contar + total_df['X2']\n",
    "\n",
    "total_df['X3'] = total_df['review'].str.contains('no', case=False).astype(int)\n",
    "total_df['X4'] = total_df['review'].str.count('i ') + \\\n",
    "    total_df['review'].str.count('I ')   + \\\n",
    "    total_df['review'].str.count('I\\'')  + \\\n",
    "    total_df['review'].str.count('i\\'')  + \\\n",
    "    total_df['review'].str.count('you ') + \\\n",
    "    total_df['review'].str.count('You ') + \\\n",
    "    total_df['review'].str.count(' u ')  + \\\n",
    "    total_df['review'].str.count(' U ')  + \\\n",
    "    total_df['review'].str.count(' u\\'')\n",
    "\n",
    "total_df['X5'] = total_df['review'].str.contains('!', case=False).astype(int)\n",
    "total_df['X6'] = np.log(total_df['review'].str.count('').add(1))\n",
    "\n",
    "total_df.tail()\n",
    "\n",
    "#print 'example: ',positivos[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.240650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7.138073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7.426549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.948035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.551080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment   X1  X2  X3  \\\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1   90  30   1   \n",
       "1  OK... so... I really like Kris Kristofferson a...          0   82  41   1   \n",
       "2  ***SPOILER*** Do not read this, if you think a...          0  108  47   1   \n",
       "3  hi for all the people who have seen this wonde...          1   31   7   0   \n",
       "4  I recently bought the DVD, forgetting just how...          0   39  25   0   \n",
       "\n",
       "   X4  X5        X6  \n",
       "0   0   0  7.240650  \n",
       "1   8   1  7.138073  \n",
       "2   6   1  7.426549  \n",
       "3   7   0  5.948035  \n",
       "4   3   0  6.551080  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#guardamos los datos \n",
    "total_df.to_csv('Total_Features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90.        ,  30.        ,   1.        ,   0.        ,\n",
       "          0.        ,   7.24064969],\n",
       "       [ 82.        ,  41.        ,   1.        ,   8.        ,\n",
       "          1.        ,   7.13807303],\n",
       "       [108.        ,  47.        ,   1.        ,   6.        ,\n",
       "          1.        ,   7.42654907],\n",
       "       ...,\n",
       "       [ 36.        ,  12.        ,   1.        ,   4.        ,\n",
       "          1.        ,   6.52356231],\n",
       "       [ 37.        ,  22.        ,   1.        ,   0.        ,\n",
       "          0.        ,   6.30261898],\n",
       "       [ 18.        ,   3.        ,   0.        ,   3.        ,\n",
       "          0.        ,   5.46806014]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.read_csv('Total_Features.csv')\n",
    "\n",
    "#my_df.tail()\n",
    "my_df.drop('review',1, inplace=True)\n",
    "#my_df.drop('Unnamed',1, inplace=True)\n",
    "my_x_train = my_df.iloc[:,2:8].values # cogiendo todos los primero valores\n",
    "my_y_train = my_df.iloc[:,1:2].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero ahora vamos a mostrar la relacion mediante un gráfico asi que ahora mostramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importar la libreria de graficos \n",
    "import seaborn as sns\n",
    "\n",
    "#sns.distplot(df['A']);\n",
    "dato = pd.read_csv('6Features.csv')\n",
    "sns.distplot(dato['A']);\n",
    "#dato.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapa de correlación (heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#matriz de correlacion con mapa de calor\n",
    "matCorr = dato.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(matCorr, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador de SGD \n",
    "\n",
    "el clasificador SGD va instanciar al clasificador lineal de regresion logistica que aprende de los documentos incrementando estocasticamente con un gradiente descendiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.         14.          1.          1.          0.          4.86753445]\n",
      " [13.         10.          1.         15.          1.          4.87519732]\n",
      " [14.         21.          1.          6.          1.          5.06259503]\n",
      " [ 4.          0.          0.          7.          0.          3.76120012]\n",
      " [ 4.          2.          0.          3.          0.          4.17438727]\n",
      " [ 9.          3.          1.          6.          0.          4.29045944]\n",
      " [15.          4.          1.          7.          0.          5.18178355]\n",
      " [ 4.          4.          1.          1.          1.          4.30406509]\n",
      " [ 6.          3.          1.          4.          1.          4.20469262]\n",
      " [10.          4.          1.          0.          1.          4.40671925]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# importar clasificador modelo lineal SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log', random_state = 1, max_iter = 1)\n",
    "doc_stream = stream_doc(path='shuffled_movie_data.csv')\n",
    "\n",
    "# Excercise 2: implement a Logistic Regression classifier, using regularization, according to https://web.stanford.edu/~jurafsky/slp3/5.pdf\n",
    "\n",
    "#importar el clasificador Regresion Lineal Logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# asignaremos primero los valores x e Y\n",
    "\n",
    "x = df.iloc[:,:-1].values # cogiendo todos los primero valores\n",
    "y = df.iloc[:,6].values\n",
    "print x\n",
    "print len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bien, ahora tenemos importado el clasificador pasando por el doc_stream, listo paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression implementacion\n",
    "\n",
    "acontinuacion vamos mostramos los mismos resultados con nuestra implementacion de la Regresion Logistica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n",
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "# My Regresion\n",
    "import random\n",
    "import numpy as np  # multidimensional array \n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\n",
    "    # inicializar\n",
    "\n",
    "    def __init__(self, X, Y, alpha=0.0005, lam=0.1, printIter=True):\n",
    "\n",
    "        x = np.array(X)\n",
    "        #x= X\n",
    "        print X.shape\n",
    "        m, n = x.shape\n",
    "\n",
    "        # normalizar data\n",
    "        self.xMean = np.mean(x, axis=0)\n",
    "        self.xStd = np.std(x, axis=0)\n",
    "        x = (x - self.xMean) / self.xStd\n",
    "\n",
    "        # agregar const column a X\n",
    "        const = np.array([1] * m).reshape(m, 1)\n",
    "        self.X = np.append(const, x, axis=1)\n",
    "\n",
    "        self.Y = np.array(Y)\n",
    "        self.alpha = alpha\n",
    "        self.lam = lam\n",
    "        self.theta = np.array([0.0] * (n + 1))\n",
    "       # print 't: ',self.theta\n",
    "        self.printIter = printIter\n",
    "        #print \"lambda=\", self.lam\n",
    "\n",
    "    # funccion de transformacion sigmoide\n",
    "    def _sigmoid(self, x):\n",
    "        #m,n = x.shape\n",
    "        #z = np.array([0.0]*(m*n)).reshape(m,n)\n",
    "        z = 1.0 / (1.0 + np.exp((-1) * x))\n",
    "        return z\n",
    "\n",
    "    # calcular costo\n",
    "    def _costFunc(self):\n",
    "        \"calculate cost\"\n",
    "        m, n = self.X.shape\n",
    "        h_theta = self._sigmoid(np.dot(self.X, self.theta))\n",
    "\n",
    "        cost1 = (-1) * self.Y * np.log(h_theta)\n",
    "        cost2 = (1.0 - self.Y) * np.log(1.0 - h_theta)\n",
    "\n",
    "        cost = (\n",
    "            sum(cost1 - cost2) + 0.5 * self.lam * sum(self.theta[1:] ** 2)) / m\n",
    "        return cost\n",
    "\n",
    "    # gradient descend\n",
    "    def _gradientDescend(self, iters):\n",
    "        \"\"\"\n",
    "        gradiente descendiente:\n",
    "        X: matriz de feature\n",
    "        Y: respuesta\n",
    "        theta: parametro a predecir\n",
    "        alpha: taza de aprendizaje\n",
    "        lam: lambda, penalidad en theta\n",
    "       \"\"\"\n",
    "        m, n = self.X.shape\n",
    "\n",
    "        # print \"m,n=\" , m,n\n",
    "        # print \"theta\", len(self.theta)\n",
    "\n",
    "        for i in range(0, iters):\n",
    "            theta_temp = self.theta\n",
    "\n",
    "            # update theta[0]\n",
    "            h_theta = self._sigmoid(np.dot(self.X, self.theta))\n",
    "            diff = h_theta - self.Y\n",
    "            self.theta[0] = theta_temp[0] - self.alpha * \\\n",
    "                (1.0 / m) * sum(diff * self.X[:, 0])\n",
    "\n",
    "            for j in xrange(1, n):\n",
    "                val = theta_temp[\n",
    "                    j] - self.alpha * (1.0 / m) * (sum(diff * self.X[:, j]) + self.lam * m * theta_temp[j])\n",
    "                # print val\n",
    "                self.theta[j] = val\n",
    "            # calcular costo y mostrar print\n",
    "            cost = self._costFunc()\n",
    "\n",
    "            if self.printIter:\n",
    "                print \"Iteration\", i, \"\\tcost=\", cost\n",
    "                # print \"theta\", self.theta\n",
    "\n",
    "    # ejecutar\n",
    "    def run(self, iters, printIter=True):\n",
    "        self.printIter = printIter\n",
    "        self._gradientDescend(iters)\n",
    "        \n",
    "    # prediccion\n",
    "    def predict(self, X):\n",
    "\n",
    "        # add const column\n",
    "        m, n = X.shape\n",
    "        x = np.array(X)\n",
    "        x = (x - self.xMean) / self.xStd\n",
    "        const = np.array([1] * m).reshape(m, 1)\n",
    "        X = np.append(const, x, axis=1)\n",
    "\n",
    "        pred = self._sigmoid(np.dot(X, self.theta))\n",
    "        np.putmask(pred, pred >= 0.5, 1.0)\n",
    "        np.putmask(pred, pred < 0.5, 0.0)\n",
    "\n",
    "        return pred\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#model \n",
    "initial_theta = [0,0]\n",
    "alpha = 0.1\n",
    "iterations = 1000\n",
    "##Logistic_Regression(X,Y,alpha,initial_theta,iterations)\n",
    "classes = np.array([0,1])\n",
    "tes_x = x\n",
    "yt = y\n",
    "for _ in range(45):\n",
    "    #Logistic_Regression(x,y,alpha, initial_theta, iterations)\n",
    "#    X_train, y_train = get_minibatch(doc_stream, size=100)\n",
    "#    X_train = vect.transform(X_train) # transforma una secuencia de documentos en una secuencia de matriz\n",
    "    #print X_train.shape\n",
    "    model = LogisticRegression(x, y, alpha=0.05, lam=0.1)\n",
    "    model.run(400, printIter=False)\n",
    "    #Logistic_Regression(X_train, y_train, alpha, initial_theta,iterations)\n",
    "\n",
    "#xTes,Ytest = get_minibatch(doc_stream, size=5000)\n",
    "#xTes = vect.transform(xTes)\n",
    "\n",
    "yts = model.predict(tes_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementacion con Logistic Regression (Sklearn)\n",
    "\n",
    "acontinuacion presentamos la implementacion de la regresion logistica de sklearn con la clasificacion de caracteristicas del Hashingvectorizer  y mas abajo mostramos el acuraci obtenido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting logistic regression to the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#import pyprind\n",
    "#pbar = pyprind.ProgBar(45)\n",
    "\n",
    "'''\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    X_train = vect.transform(X_train) # transforma una secuencia de documentos en una secuencia de matriz\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    #pbar.update()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classes = np.array([0,1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    X_train = vect.transform(X_train) # transforma una secuencia de documentos en una secuencia de matriz\n",
    "    classifier.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn LR Accuracy:  0.797\n",
      "my own Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "xTes,Ytest = get_minibatch(doc_stream, size=5000)\n",
    "xTes = vect.transform(xTes)\n",
    "classifier.predict(xTes)\n",
    "\n",
    "#medir el accuracy obtenido por medio de la regresion lineal de sklearn\n",
    "#metric el accurary score\n",
    "from sklearn import metrics\n",
    "\n",
    "print'sklearn LR Accuracy: ',(metrics.accuracy_score(Ytest,classifier.predict(xTes)))\n",
    "print 'my own Accuracy:',metrics.accuracy_score(yts,yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el acuracy de sklearn es 80% para con el hashingvectorizer, asi tambien podemos observar que la implementacion propia tiene un acuracy de 90%\n",
    "\n",
    "### training using SGDclassification from sklearn\n",
    "\n",
    "la implementación siguiente es la version original del tutorial con el vector hashingvectorizer asi como "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    X_train = vect.transform(X_train) # transforma una secuencia de documentos en una secuencia de matriz\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    #pbar.update()\n",
    "\n",
    "# finalmente obtenemos el accuracy\n",
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(ytr, yts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
